python -m torch.distributed.launch --nproc_per_node 2 examples/run_classifier.py --model_type roberta --model_name_or_path /model/yaoyinnan/roberta-base --task_name Fakeddit2way --do_lower_case --data_dir /data/yaoyinnan/Fakeddit/2way --max_seq_length 128 --per_gpu_train_batch_size 48 --per_gpu_eval_batch_size 512 --per_gpu_test_batch_size 512 --per_gpu_pred_batch_size 512 --learning_rate 5e-5 --weight_decay 0.0001 --num_train_epochs 1.0 --output_dir /output/Fakeddit/Fakeddit2way-roberta-base/stage_1 --save_steps 15 --eval_all_checkpoints --overwrite_cache --do_test --do_eval --do_train